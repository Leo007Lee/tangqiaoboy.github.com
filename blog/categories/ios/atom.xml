<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: iOS | 唐巧的技术博客]]></title>
  <link href="http://blog.devtang.com/blog/categories/ios/atom.xml" rel="self"/>
  <link href="http://blog.devtang.com/"/>
  <updated>2012-11-10T21:31:26+08:00</updated>
  <id>http://blog.devtang.com/</id>
  <author>
    <name><![CDATA[唐巧]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[改进iOS客户端的升级提醒功能]]></title>
    <link href="http://blog.devtang.com/blog/2012/11/10/how-to-design-upgrade-notice/"/>
    <updated>2012-11-10T18:42:00+08:00</updated>
    <id>http://blog.devtang.com/blog/2012/11/10/how-to-design-upgrade-notice</id>
    <content type="html"><![CDATA[<h2>功能设计</h2>

<p>先申明一下，我是码农，不是一个产品经理，但我觉得现有市面上的很多App，在设计“升级提示功能”都有问题。在此分享一下我的想法，欢迎大家讨论。</p>

<p>这些有问题的App包括：新浪微博、网易微博、网易新闻客户端以及大部分带有升级提示功能的App，所以我觉得这个问题还是挺普遍的。对于该问题，一句话描述起来就是：“这些App都会在用户刚刚使用它的时候，提示有新版本，让用户去AppStore上下载最新的版本”。下面是某个应用的升级提示截图：</p>

<p><img src="/images/app-upgrade-1.png"></p>

<p>为什么我认为这是一个糟糕的设计呢？因为用户刚刚打开你的App，明显就是想使用你的功能。例如刚刚打开新浪微博，可能就是想看一下最新的消息或回复。刚刚打开网易新闻客户端，可能就是想看看最新的新闻。这个时候，你告诉用户有新版本，是想让用户暂时放弃使用该App吗？我不知道有多少用户会去点“升级”这个按钮，反正我每次看到这个提示都很郁闷，因为我如果点了，我就暂时不能使用该应用了（升级时原版本的App是无法使用的）。所以我在想，这个提示升级的时间能不能做得更友好一些？</p>

<!-- more -->


<p>有一次在地铁上我想到了一个好办法，就是让升级提示不是出现在软件刚刚打开的时候，而是用户刚刚退出App的时候，我们可以在用户刚刚退出App的时候，向iOS设备发一个本地的通知(Local Notification)，在本地通知上显示升级提示。当用户点击这个升级提示时，我们的App在启动后跳转到AppStore，这样就达到的提示升级的效果。</p>

<p>这样做相比以前的好处有以下几点：</p>

<ol>
<li>用户退出App的时刻，是一个访问这个App活动的结束。在这个时候提示，用户更有理由接受升级。</li>
<li>即便用户当前不接受升级，但这个升级提示都会存在用户的通知中心中，用户想升级时，点击这个通知，就可以方便地一键跳到AppStore的下载页面。而之前的方法在用户取消后，用户就不方便取获下载地址了。</li>
</ol>


<p>另外，本地通知的使用只需要iOS4.0以上版本即可，而在中国，<a href="http://www.zhihu.com/question/20267080">iOS4.0以上比例</a>达到了99%。本地通知也不需要向用户申请发送通知的DeviceToken，所以该方案很少被用户禁止（用户只能专门去通知中心将该应用的所有通知关闭）。当然，这个升级提示也不应该每次都出现，以免对用户产生太多打挠，象我在粉笔网客户端上设置的策略是最多半个月出现一次。</p>

<p>在我在粉笔网iPhone端实现该方案后，有一次我发现支付宝的iOS客户端也采用通知的方式来提示用户升级，看来大家都想到一块儿了。不过从通知的发送时间来看，他们应该不是使用的本地通知，而是通过服务器发送Push通知的方式。这种方式的好处是即使用户安装后一次也没有使用你的App，你还是可以通过通知来唤醒他，可能的坏处是：</p>

<ol>
<li>可能用户已经升完级了，你还把升级通知的信息发给用户了。象我就是，支付宝都升完级了，还发通知提示我有新版可以使用。</li>
<li>用户如果禁止了应用的Push通知，你就没办法发送升级提醒了。</li>
</ol>


<h2>技术实现</h2>

<p>再简单说一下技术实现，我写了一个VersionAgent类，每24小时最多向服务器请求一次最新的App版本，如果版本有更新，则在AppDelegate的applicationDidEnterBackgroundl回调中，发送一个本地通知，示例代码如下：</p>

<p>``` objc
- (void)applicationDidEnterBackground:(UIApplication *)application
{</p>

<pre><code>if ([[VersionAgent sharedInstance] shouldShowLocalNotification]) {
    dispatch_async(dispatch_get_main_queue(), ^{
        UILocalNotification * localNotification = [[UILocalNotification alloc] init];
        if (localNotification) {
            localNotification.fireDate= [[[NSDate alloc] init] dateByAddingTimeInterval:3];
            localNotification.timeZone=[NSTimeZone defaultTimeZone];
            localNotification.alertBody = @"粉笔网客户端有新的版本，点击到App Store升级。";
            localNotification.alertAction = @"升级";
            localNotification.soundName = @"";
            [application scheduleLocalNotification:localNotification];
        }
    });
}
</code></pre>

<p>}
```</p>

<p>然后通过AppDelegate的回调函数，判断App的启动方式是否是通过用户点击通知中心的升级提示来启动，如果是，则跳转到AppStore，示例代码如下：
``` objc
- (void)application:(UIApplication <em>)application didReceiveLocalNotification:(UILocalNotification </em>)notification {</p>

<pre><code>// open app store link
NSString * url = [NSString stringWithFormat:@"itms-apps://itunes.apple.com/app/id%@", APP_STORE_ID];
[[UIApplication sharedApplication] openURL:[NSURL URLWithString:url]];
</code></pre>

<p>}</p>

<p>```</p>

<h2>题外话</h2>

<p><img src="/images/app-upgrade-2.jpeg"></p>

<p>最新微博上有一个<a href="http://www.chinanews.com/sh/2012/11-09/4315347.shtml?utm_source=bshare&amp;utm_campaign=bshare&amp;utm_medium=sinaminiblog#bsh-24-154760667">新闻</a>很火，一个技术男，给女友发弹窗通知求爱。有些人回复说这样做太麻烦，需要在服务器上记DeviceToken，否则所有用户都发的话，会让很多不相关的人收到。</p>

<p>其实这完全可以用本地通知来做，完全不需要服务器配合，相当简单。
具体做法是：你自己写一个发本地求爱通知的小应用，然后记下女友手机的UDID，将女友的手机设置成开发者设备，然后抓住一次机会在其手机上安装好开发者证书和你写的这个小App即可。可以把这个App隐藏在某个文件夹下面，然后打开一次，设置好本地通知的发出时间即可。</p>

<p>我的很多文章最后结尾都是Have fun，不过最近很难高兴起来啊。因为0x12 Big，今天google的全线产品都无法访问了。想起我每天的工作都是用google搜技术贴，用gmail收邮件，用gtalk聊天，我的联系人信息，备忘录也是同步在google contact上，我真的无法fun起来了。本博客是架设在github上的，我也很担心该博客可能也会因为是境外IP而被禁止访问。</p>

<p>有时候，我很气愤，而有时候，我会乐观地想，这些都是负能量的积累，黎明前的黑暗。不管怎么样，谁也无法阻止大家对自由的向往，希望有朝一日，所有人都能自由地获取信息。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在MacOS和iOS系统中使用OpenCV]]></title>
    <link href="http://blog.devtang.com/blog/2012/10/27/use-opencv-in-ios/"/>
    <updated>2012-10-27T20:43:00+08:00</updated>
    <id>http://blog.devtang.com/blog/2012/10/27/use-opencv-in-ios</id>
    <content type="html"><![CDATA[<h2>前言</h2>

<p><img src="/images/opencv.png"></p>

<p><a href="http://opencv.org/about.html">OpenCV</a> 是一个开源的跨平台计算机视觉库，实现了图像处理和计算机视觉方面的很多通用算法。</p>

<p>最近试着在MacOS和iOS上使用OpenCV，发现网上关于在MacOS和iOS上搭建OpenCV的资料很少。好不容易搜到些资料，却发现由于OpenCV和XCode的版本更新，变得不再有用了。有些问题费了我很多时间，在此总结分享给大家，希望后来人少走些弯路。</p>

<p>可以预见到，随着XCode和OpenCV的版本更新，本文可能不再有效了。所以特此注明，文本介绍的搭建方法仅针对于 XCode4.5.1 和 OpenCV 2.4.2版本。</p>

<!-- more -->


<h2>MacOS系统中使用OpenCV</h2>

<h3>安装OpenCV</h3>

<p>相信大部分Mac用户都安装了brew或port，如果你没有装，那么首先安装一下brew吧。使用如下命令安装brew:</p>

<p><code>bash
ruby -e "$(curl -fsSkL raw.github.com/mxcl/homebrew/go)"
</code></p>

<p>在安装好brew后，只需要一条命令就可以安装OpenCV了：
<code>bash
brew install opencv
</code></p>

<p>通常情况下这样做就应该会安装成功，但我在公司和家里面的电脑尝试的时候，brew都会报一些错误，我遇到的都是一些小问题，按照brew的提示信息，解决掉相应的问题即可。</p>

<p>安装成功后，你应该可以在“/usr/local/include"目录下找到名为opencv和opencv2的目录，这里面是OpenCV相关的头文件。你也可以在“/usr/local/lib"目录下找到许多以libopencv_开头的.dylib文件，这些是OpenCV的链接库文件。</p>

<h3>在MacOS系统中使用OpenCV</h3>

<p>接着我们可以试着在Xcode工程中使用OpenCV。</p>

<p>新建一个Cocoa Application的工程。工程建好后，选中工程的Target，在Build Settings一样，找到“Header Search Paths"这一个选项，将它的值改为“/usr/local/include"。如下所示：</p>

<p><img src="/images/use-opencv-in-mac-1.png"></p>

<p>接着切换到Build Phases这个tab，在“Link Binary With Libraries"中，选项+号，然后将弹出的文件选择对话框目录切换到“/usr/local/lib"目录下，选择你需要使用的OpenCV链接库（通常情况下，你至少会需要core、highgui和imgproc库)，如下图所示：</p>

<p><img src="/images/use-opencv-in-mac-2.png"></p>

<p>这里有一个技巧，因为 /usr 目录在对话框中默认不是可见的，可以按快捷键 command + shift + G，在弹出的“前往文件夹"对话框中输入 /usr/local/lib ，即可跳转到目标文件夹。如下图所示：</p>

<p><img src="/images/use-opencv-in-mac-3.png"></p>

<p>下一步是我自己试出来的，你需要在Build Settings中，将“C++ Language Dialect”设置成C++11，将“C++ Standard Library”设置成libstdc++ ，如下图所示。个人感觉是由于XCode默认设置的GNU++11、libc++与OpenCV库有一些兼容性问题，我在更改该设置前老是出现编译错误。如果后续版本解决了这个问题，就不用进行这一步了。</p>

<p><img src="/images/use-opencv-in-mac-4.png"></p>

<p>把上面的设置都做好后，就可以在需要的使用OpenCV库的地方，加上opencv的头文件引用即可：</p>

<p>``` objc</p>

<h1>import "opencv2/opencv.hpp"</h1>

<p>```</p>

<p>注意，如果你的源文件扩展名是.m的，你还需要改成.mm，这样编译器才知道你将会在该文件混合使用C++语言和Objective-C语言。</p>

<p>OpenCV处理图象需要的格式是cv::Mat类，而MacOS的图象格式默认是NSImage，所以你需要知道如何在cv::Mat与NSImage之前相互转换。如下是一个NSImage的Addition，你肯定会需要它的。该代码来自stackoverflow上的<a href="http://stackoverflow.com/questions/8563356/nsimage-to-cvmat-and-vice-versa">这个贴子</a>。</p>

<p>NSImage+OpenCV.h 文件：
``` objc
//
//  NSImage+OpenCV.h
//
//  Created by TangQiao on 12-10-26.
//</p>

<h1>import &lt;Foundation/Foundation.h></h1>

<h1>import "opencv2/opencv.hpp"</h1>

<p>@interface NSImage (OpenCV)</p>

<p>+(NSImage*)imageWithCVMat:(const cv::Mat&amp;)cvMat;
-(id)initWithCVMat:(const cv::Mat&amp;)cvMat;</p>

<p>@property(nonatomic, readonly) cv::Mat CVMat;
@property(nonatomic, readonly) cv::Mat CVGrayscaleMat;</p>

<p>@end</p>

<p>```</p>

<p>NSImage+OpenCV.mm文件：
``` objc
//
//  NSImage+OpenCV.mm
//
//  Created by TangQiao on 12-10-26.
//</p>

<h1>import "NSImage+OpenCV.h"</h1>

<p>static void ProviderReleaseDataNOP(void <em>info, const void </em>data, size_t size)
{</p>

<pre><code>return;
</code></pre>

<p>}</p>

<p>@implementation NSImage (OpenCV)</p>

<p>-(CGImageRef)CGImage
{</p>

<pre><code>CGContextRef bitmapCtx = CGBitmapContextCreate(NULL/*data - pass NULL to let CG allocate the memory*/,
                                               [self size].width,
                                               [self size].height,
                                               8 /*bitsPerComponent*/,
                                               0 /*bytesPerRow - CG will calculate it for you if it's allocating the data.  This might get padded out a bit for better alignment*/,
                                               [[NSColorSpace genericRGBColorSpace] CGColorSpace],
                                               kCGBitmapByteOrder32Host|kCGImageAlphaPremultipliedFirst);

[NSGraphicsContext saveGraphicsState];
[NSGraphicsContext setCurrentContext:[NSGraphicsContext graphicsContextWithGraphicsPort:bitmapCtx flipped:NO]];
[self drawInRect:NSMakeRect(0,0, [self size].width, [self size].height) fromRect:NSZeroRect operation:NSCompositeCopy fraction:1.0];
[NSGraphicsContext restoreGraphicsState];

CGImageRef cgImage = CGBitmapContextCreateImage(bitmapCtx);
CGContextRelease(bitmapCtx);

return cgImage;
</code></pre>

<p>}</p>

<p>-(cv::Mat)CVMat
{</p>

<pre><code>CGImageRef imageRef = [self CGImage];
CGColorSpaceRef colorSpace = CGImageGetColorSpace(imageRef);
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;
cv::Mat cvMat(rows, cols, CV_8UC4); // 8 bits per component, 4 channels

CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNoneSkipLast |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), imageRef);
CGContextRelease(contextRef);
CGImageRelease(imageRef);
return cvMat;
</code></pre>

<p>}</p>

<p>-(cv::Mat)CVGrayscaleMat
{</p>

<pre><code>CGImageRef imageRef = [self CGImage];
CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceGray();
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;
cv::Mat cvMat = cv::Mat(rows, cols, CV_8UC1); // 8 bits per component, 1 channel
CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNone |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), imageRef);
CGContextRelease(contextRef);
CGColorSpaceRelease(colorSpace);
CGImageRelease(imageRef);
return cvMat;
</code></pre>

<p>}</p>

<ul>
<li><p>(NSImage *)imageWithCVMat:(const cv::Mat&amp;)cvMat
{
  return [[[NSImage alloc] initWithCVMat:cvMat] autorelease];
}</p></li>
<li><p>(id)initWithCVMat:(const cv::Mat&amp;)cvMat
{
  NSData *data = [NSData dataWithBytes:cvMat.data length:cvMat.elemSize() * cvMat.total()];</p>

<p>  CGColorSpaceRef colorSpace;</p>

<p>  if (cvMat.elemSize() == 1)
  {</p>

<pre><code>  colorSpace = CGColorSpaceCreateDeviceGray();
</code></pre>

  }
  else
  {

<pre><code>  colorSpace = CGColorSpaceCreateDeviceRGB();
</code></pre>

<p>  }</p>

<p>  CGDataProviderRef provider = CGDataProviderCreateWithCFData((CFDataRef)data);</p>

<p>  CGImageRef imageRef = CGImageCreate(cvMat.cols,                                     // Width</p>

<pre><code>                                  cvMat.rows,                                     // Height
                                  8,                                              // Bits per component
                                  8 * cvMat.elemSize(),                           // Bits per pixel
                                  cvMat.step[0],                                  // Bytes per row
                                  colorSpace,                                     // Colorspace
                                  kCGImageAlphaNone | kCGBitmapByteOrderDefault,  // Bitmap info flags
                                  provider,                                       // CGDataProviderRef
                                  NULL,                                           // Decode
                                  false,                                          // Should interpolate
                                  kCGRenderingIntentDefault);                     // Intent
</code></pre>

<p>  NSBitmapImageRep <em>bitmapRep = [[NSBitmapImageRep alloc] initWithCGImage:imageRef];
  NSImage </em>image = [[NSImage alloc] init];
  [image addRepresentation:bitmapRep];</p>

<p>  CGImageRelease(imageRef);
  CGDataProviderRelease(provider);
  CGColorSpaceRelease(colorSpace);</p>

<p>  return image;
}</p></li>
</ul>


<p>@end</p>

<p>```</p>

<p>完成以上步骤后，恭喜你，你可以在源代码中自由地调用OpenCV的函数了。</p>

<h2>在iOS系统中使用OpenCV</h2>

<h4>下载或编译opencv2.framework</h4>

<p>接下来介绍如何在iOS程序中使用OpenCV。在iOS上使用最新的OpenCV库比较简单，进入<a href="http://opencv.org/">opencv的官网</a>，下载build好的名为opencv2.framework即可（<a href="http://sourceforge.net/projects/opencvlibrary/files/opencv-ios/2.4.3/opencv2.framework.zip/download?utm_expid=6384-3">下载地址</a>）。</p>

<p>如果你比较喜欢折腾，也可以自行下载opencv的源码，在本地编译opencv2.framework。<a href="http://docs.opencv.org/trunk/doc/tutorials/introduction/ios_install/ios_install.html#ios-installation">这里</a>有官方网站的教程，步骤非常简单，不过我照着它的教程尝试了一下失败了。感觉还是XCode编译器与OpenCV代码的兼容性问题，所以就没有继续研究了。</p>

<h4>在iOS程序中使用OpenCV</h4>

<p>新建一个iOS工程，将opencv2.framework直接拖动到工程中。然后，你需要在Build Settings中，将“C++ Standard Library”设置成libstdc++。</p>

<p>因为opencv中的MIN宏和UIKit的MIN宏有冲突。所以需要在.pch文件中，先定义opencv的头文件，否则会有编译错误。将工程的.pch文件内容修改成如下所示：</p>

<p>``` objc</p>

<h1>import &lt;Availability.h></h1>

<h1>ifdef __cplusplus</h1>

<pre><code>#import &lt;opencv2/opencv.hpp&gt;
</code></pre>

<h1>endif</h1>

<h1>ifdef <strong>OBJC</strong></h1>

<pre><code>#import &lt;UIKit/UIKit.h&gt;
#import &lt;Foundation/Foundation.h&gt;
</code></pre>

<h1>endif</h1>

<p>```</p>

<p>把上面的设置都做好后，就可以在需要的使用OpenCV库的地方，加上opencv的头文件引用即可：</p>

<p>``` objc</p>

<h1>import "opencv2/opencv.hpp"</h1>

<p>```</p>

<p>还是那句话，如果你的源文件扩展名是.m的，你还需要改成.mm，这样编译器才知道你将会在该文件中混合使用C++语言和Objective-C语言。</p>

<p>同样，iOS程序内部通常用UIImage表示图片，而OpenCV处理图象需要的格式是cv::Mat，你会需要下面这个Addition来在cv::Mat和UIImage格式之间相互转换。该代码来自<a href="https://github.com/aptogo/OpenCVForiPhone">aptogo的开源代码</a>，他的版权信息在源码头文件中。</p>

<p>UIImage+OpenCV.h 文件：
``` objc
//
//  UIImage+OpenCV.h
//  OpenCVClient
//
//  Created by Robin Summerhill on 02/09/2011.
//  Copyright 2011 Aptogo Limited. All rights reserved.
//
//  Permission is given to use this source code file without charge in any
//  project, commercial or otherwise, entirely at your risk, with the condition
//  that any redistribution (in part or whole) of source code must retain
//  this copyright and permission notice. Attribution in compiled projects is
//  appreciated but not required.
//</p>

<h1>import &lt;UIKit/UIKit.h></h1>

<p>@interface UIImage (UIImage_OpenCV)</p>

<p>+(UIImage *)imageWithCVMat:(const cv::Mat&amp;)cvMat;
-(id)initWithCVMat:(const cv::Mat&amp;)cvMat;</p>

<p>@property(nonatomic, readonly) cv::Mat CVMat;
@property(nonatomic, readonly) cv::Mat CVGrayscaleMat;</p>

<p>@end</p>

<p>```</p>

<p>UIImage+OpenCV.mm 文件：
``` objc
//
//  UIImage+OpenCV.mm
//  OpenCVClient
//
//  Created by Robin Summerhill on 02/09/2011.
//  Copyright 2011 Aptogo Limited. All rights reserved.
//
//  Permission is given to use this source code file without charge in any
//  project, commercial or otherwise, entirely at your risk, with the condition
//  that any redistribution (in part or whole) of source code must retain
//  this copyright and permission notice. Attribution in compiled projects is
//  appreciated but not required.
//</p>

<h1>import "UIImage+OpenCV.h"</h1>

<p>static void ProviderReleaseDataNOP(void <em>info, const void </em>data, size_t size)
{</p>

<pre><code>// Do not release memory
return;
</code></pre>

<p>}</p>

<p>@implementation UIImage (UIImage_OpenCV)</p>

<p>-(cv::Mat)CVMat
{</p>

<pre><code>CGColorSpaceRef colorSpace = CGImageGetColorSpace(self.CGImage);
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;

cv::Mat cvMat(rows, cols, CV_8UC4); // 8 bits per component, 4 channels

CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNoneSkipLast |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), self.CGImage);
CGContextRelease(contextRef);

return cvMat;
</code></pre>

<p>}</p>

<p>-(cv::Mat)CVGrayscaleMat
{</p>

<pre><code>CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceGray();
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;

cv::Mat cvMat = cv::Mat(rows, cols, CV_8UC1); // 8 bits per component, 1 channel

CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNone |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), self.CGImage);
CGContextRelease(contextRef);
CGColorSpaceRelease(colorSpace);

return cvMat;
</code></pre>

<p>}</p>

<ul>
<li><p>(UIImage *)imageWithCVMat:(const cv::Mat&amp;)cvMat
{
  return [[[UIImage alloc] initWithCVMat:cvMat] autorelease];
}</p></li>
<li><p>(id)initWithCVMat:(const cv::Mat&amp;)cvMat
{
  NSData *data = [NSData dataWithBytes:cvMat.data length:cvMat.elemSize() * cvMat.total()];</p>

<p>  CGColorSpaceRef colorSpace;</p>

<p>  if (cvMat.elemSize() == 1)
  {</p>

<pre><code>  colorSpace = CGColorSpaceCreateDeviceGray();
</code></pre>

  }
  else
  {

<pre><code>  colorSpace = CGColorSpaceCreateDeviceRGB();
</code></pre>

<p>  }</p>

<p>  CGDataProviderRef provider = CGDataProviderCreateWithCFData((CFDataRef)data);</p>

<p>  CGImageRef imageRef = CGImageCreate(cvMat.cols,                                     // Width</p>

<pre><code>                                  cvMat.rows,                                     // Height
                                  8,                                              // Bits per component
                                  8 * cvMat.elemSize(),                           // Bits per pixel
                                  cvMat.step[0],                                  // Bytes per row
                                  colorSpace,                                     // Colorspace
                                  kCGImageAlphaNone | kCGBitmapByteOrderDefault,  // Bitmap info flags
                                  provider,                                       // CGDataProviderRef
                                  NULL,                                           // Decode
                                  false,                                          // Should interpolate
                                  kCGRenderingIntentDefault);                     // Intent   
</code></pre>

<p>  self = [self initWithCGImage:imageRef];
  CGImageRelease(imageRef);
  CGDataProviderRelease(provider);
  CGColorSpaceRelease(colorSpace);</p>

<p>  return self;
}</p></li>
</ul>


<p>@end</p>

<p>```</p>

<h2>总结</h2>

<p>上面2个环境搭建好后，你就可以在MacOS上试验各种图象处理算法，然后很方便地移值到iOS上。</p>

<p>一直觉得，图象和声音是移动设备上的特点和优势。因为移动设备没有了可以快速输入的键盘，屏幕也不大，在移动设备上，声音，图象和视频应该是相比文字更方便让人输入的东西。移动端APP应该利用好这些特点，才能设计出更加体贴的功能。</p>

<p>而且，通常情况下做图象处理都比较好玩，记得以前在学校做了一个在QQ游戏大厅自动下中国象棋的程序，其后台使用了网上下载的一个带命令行接口的象棋AI，然后我的代码主要做的事情就是识别象棋棋盘，然后将棋盘数据传给那个象棋AI，接着获得它返回的策略后，模拟鼠标点击来移动棋子。当时不懂什么图象算法，直接把棋子先截取下来保存，然后识别的时候做完全匹配，非常弱的办法，但是效果非常好，做出来也很好玩。嗯，所以文章最后，我想说的是：have fun!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[粉笔网iPhone端使用的第三方开源库]]></title>
    <link href="http://blog.devtang.com/blog/2012/10/09/3rd-libs-used-in-fenbi-app/"/>
    <updated>2012-10-09T15:30:00+08:00</updated>
    <id>http://blog.devtang.com/blog/2012/10/09/3rd-libs-used-in-fenbi-app</id>
    <content type="html"><![CDATA[<h2>前言</h2>

<p>最近有朋友问我粉笔网iPhone端使用了哪些第三方的开源库。我在这儿整理了一下，分享给大家。</p>

<p><img src="/images/fenbi_libs.png"></p>

<!-- more -->


<h3>ASIHttpRequest</h3>

<p><a href="http://allseeing-i.com/ASIHTTPRequest/">ASIHttpRequest</a> 是一个被广泛使用的第三方网络访问开源库。用于提供更加友好的网络访问接口。相信很多搞iOS开发的朋友都用过它。
ASIHttpRequest 的主要使用文档可以<a href="http://allseeing-i.com/ASIHTTPRequest/How-to-use">参考这里</a>。</p>

<p>另外，由于ASIHTTPRequest的作者已经公开说明不再维护这个开源项目，并且该项目已经一年多没有更新了，所以我一直在寻找替代的开源库。不过现在暂时还没有找到更好的。</p>

<h3>RegexKit</h3>

<p><a href="http://regexkit.sourceforge.net/">RegexKit</a>是一个正则表达式工具类。提供强大的正则表达式匹配和替换功能。我们主要使用它来对类似微博的正文替换工作。例如将 @某某 换成带链接的，将图片的URL换成img标签等。</p>

<p>同时，开源库MGTemplateEngine也依赖于此库。附上<a href="http://regexkit.sourceforge.net/Documentation/index.html">RegexKit4.0的官方文档教程</a>。</p>

<h3>MGTemplateEngine</h3>

<p><a href="http://svn.cocoasourcecode.com/MGTemplateEngine">MGTemplateEngine</a>是一个模版引擎。我们主要使用它来生成单条微博页的内容。我们的单条微博页打算用UIWebView来显示，所以内容需要用模版渲染成HTML格式。MGTemplateEngine的模版语言比较象：Smarty, FreeMarker 和 Django的模版语言。</p>

<p>MGTemplateEngine的作者官方博客在<a href="http://mattgemmell.com/2008/05/20/mgtemplateengine-templates-with-cocoa/">这里</a>。</p>

<p>我们在使用时，对此开源库的Filter类进行了修改，主要增加了3个自定义的filter，用于提供我们的格式化时间，转义html和过滤空头象的用户的方式。</p>

<h3>JSONKit</h3>

<p><a href="https://github.com/johnezang/JSONKit">JSONKit</a>是一个比较高效的JSON解析库。我之前比较过各大JSON解析库的性能（<a href="http://blog.devtang.com/blog/2012/05/05/do-not-use-sbjson/">文章在此</a>），JSONKit算是非常不错的，大概的使用示例如下：</p>

<p>``` objc</p>

<h1>import "JSONKit.h"</h1>

<p>NSString <em>path = [[NSBundle mainBundle] pathForResource:@"data" ofType:@"json"];
NSData </em>content = [NSData dataWithContentsOfFile:path];
NSDictionary <em>kitData = [content objectFromJSONData];
NSString </em>kitString = [kitData JSONString];
```</p>

<h3>GTMNSString</h3>

<p><a href="https://code.google.com/p/google-toolbox-for-mac/">GTMNSString</a>主要用于转义HTML中的特殊字符。以防止XSS攻击。</p>

<h3>FMDB</h3>

<p><a href="https://github.com/ccgus/fmdb">FMDB</a>是一个sqlite数据库封装类，需要加入 libsqlite3.dylib 依赖以及引入 sqlite3.h 头文件即可。在使用上非常简单。如下是一个例子：</p>

<p>``` objc
NSString * docsdir = [NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES) lastObject];
NSString * dbpath = [docsdir stringByAppendingPathComponent:@"user.sqlite"];
FMDatabase * db = [FMDatabase databaseWithPath:dbpath];
[db open];
FMResultSet * rs = [db executeQuery:@"select * from People"];
while ([rs next]) {</p>

<pre><code>NSLog(@"%@ %@",
[rs stringForColumn:@"firstname"],
[rs stringForColumn:@"lastname"]);
</code></pre>

<p>}
[db close];
```</p>

<h3>BBCustomBackButtonViewController</h3>

<p><a href="https://github.com/typeoneerror/BBCustomBackButtonViewController">BBCustomBackButtonViewController</a> 是用于在ios4上提供自定义的NavigationBar按钮的开源库。使用上异常简单，只需要让自己的ViewController继承它就可以了。</p>

<p>我对BBCustomBackButtonViewController进行了修改，主要是改动它的自定义的按钮的样式，使其和我们的风格一致。</p>

<h3>MTStatusBarOverlay</h3>

<p><a href="https://github.com/myell0w/MTStatusBarOverlay">MTStatusBarOverlay</a> 是一个在iphone的顶部status bar显示消息的开源库。示例代码如下：</p>

<p>``` objc
+ (void)showCompletedTextOnStatusBar:(NSString *)text {</p>

<pre><code>NSString * message = [NSString stringWithFormat:@"%@成功", text];
MTStatusBarOverlay *overlay = [MTStatusBarOverlay sharedInstance];
overlay.animation = MTStatusBarOverlayAnimationFallDown;
overlay.detailViewMode = MTDetailViewModeHistory;
[overlay postImmediateFinishMessage:message duration:2.0 animated:YES];
overlay.progress = 1.0;
</code></pre>

<p>}
```</p>

<p>但是stackoverflow上说，有项目因为这个审核被拒，但是新浪微博明显采用了此UI方案，所以我们还是大胆用了这个库。后来，我们也顺利通过了审核。</p>

<h3>MBProgressHUD</h3>

<p><a href="https://github.com/jdg/MBProgressHUD">MBProgressHUD</a> 是一个用于显示灰色的加载进度或结果的类。与系统自带的UIAlertView相比，MBProgressHUD由于背影是黑色的，所以视觉上不是那么强烈。我们主要用它来显示一些加载中的提示，以及一些自已会消失的操作结果（例如网络失败等）。</p>

<h3>NSStringWrapper</h3>

<p>因为自己有多年Java开发的经历，我还是不太习惯Objective-C连基本的字符串操作都要查文档，而我自己又记不住老长的方法名，所以我把Objective-C的字符串基本操作都封装成了Java风格的方法调用。这部分是很早前拿周末时间在家里写的，所以是开源的，<a href="https://github.com/tangqiaoboy/xcode_tool/tree/master/NSStringWrappeer">源代码地址</a>。</p>

<h3>EGOTableViewPullRefresh</h3>

<p><a href="https://github.com/enormego/EGOTableViewPullRefresh">EGOTableViewPullRefresh</a> 一个开源的下拉刷新组件。我对它进行了改进，增加了强制刷新功能。</p>

<h3>LoadMoreTableFooterView</h3>

<p><a href="https://github.com/sishen/LoadMoreTableFooterView">LoadMoreTableFooterView</a> 一个开源的上拉加载更多的组件。我做了少量修改，以便让它支持iPhone5的分辨率。</p>

<h3>zepto.js</h3>

<p><a href="http://zeptojs.com/">zepto</a>是一个类似JQuery的javascript开源库，用于实现css选择器和一些dom操作。它的api几乎和JQuery完全一样，优点是体积小巧。</p>

<h3>ejs</h3>

<p><a href="http://embeddedjs.com/getting_started.html">ejs</a>一个js端的模版库。我们主要用于渲染一些UIWebview中异步加载的内容。例如笔记的评论，问题的答案。</p>

<h2>总结</h2>

<p>希望上面的开源库能对你有用。最后分享一张粉笔网全站用到的所有开源项目的图片。</p>

<p><img src="/images/opensource.jpg"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[让你的APP支持iPhone5]]></title>
    <link href="http://blog.devtang.com/blog/2012/10/05/upgrade-your-app-to-support-iphone5/"/>
    <updated>2012-10-05T16:18:00+08:00</updated>
    <id>http://blog.devtang.com/blog/2012/10/05/upgrade-your-app-to-support-iphone5</id>
    <content type="html"><![CDATA[<h2>前言</h2>

<p>国庆节前，为了支持iPhone5的屏幕分辨率(640象素 x 1136象素)，我尝试着升级粉笔网<a href="http://itunes.apple.com/cn/app/fen-bi-wang/id551540593">iPhone客户端</a>。整个过程花了大概一天的时间，我把这个过程总结下来，希望对大家有帮助。</p>

<!-- more -->


<h2>升级准备</h2>

<p>为了支持iPhone5，我们首先需要准备以下工具和资源：</p>

<ol>
<li>下载最新版的XCode4.5</li>
<li>让美术同学提供640 x 1136分辨率的启动画面，640 x 1136分辨率的程序截图（用于在app store中显示）</li>
<li>由于iPhone5使用的A6处理器采用了新的armv7s架构，所以如果你使用了第三方的静态链接库，需要下载对应支持armv7s的版本。我们由于使用了第三方的数据统计工具Flurry，所以下载更新了Flurry的静态链接库。</li>
<li>如果你的显示器分辨率太小，将无法显示完整的iPhone5模拟器，可选的解决办法是换个更大的显示器或者把显示器竖起来，象我这样:</li>
</ol>


<p><img src="/images/iphone5support-1.jpg"></p>

<p>另外还有一个简单的办法，可以在启动模拟器后，用快捷键command+3(50%)，command+2(75%), command+1(100%)，来调整模拟器的显示比例，谢谢<a href="http://weibo.com/arcsystemworks">Superrr一一</a> 提供的方法，比我的简单多了。</p>

<h2>具体升级步骤如下</h2>

<h4>升级启动画面和第三方链接库</h4>

<p>升级启动画面，将美术同学提供的640 x 1136分辨率的启动画面图片，命名为Default-568h@2x.png，添加到工程中即可。</p>

<p>升级第三方链接库，这个只需要用新的第三方链接库替换掉以前的即可。如果你使用了例如opencv这种需要自己编译对应版本链接库的开源库，那么替换之前，需要自己先用xcode4.5编译其armv7s版本的静态链接库。</p>

<h4>调整xib文件</h4>

<p>粉笔网客户端的界面基本上都是顶部是UINavigationBar, 底部是UITabBar或UIToolBar，中间是UITableView。</p>

<p>对于这一类界面，调整起来非常简单，只需要将UITableView设置成高度自动扩展的Autosizing方式，如下图所示：</p>

<p><img src="/images/autosizing-1.png"></p>

<p>对于底部的UIToolBar，Autosizing设置成靠底部对齐的方式即可。如下图所示：</p>

<p><img src="/images/autosizing-2.png"></p>

<h4>代码调整</h4>

<p>有一些界面元素的位置是用代码来设置的，例如“发表笔记”界面中浮动贴在输入法键盘上面的各种可选操作的UIToolbar。因为键盘的高度在不同的输入法下是不一样的，所以需要用代码动态调整。</p>

<p>我的调整代码如下：</p>

<p>``` objc</p>

<p>// 说明：keyboardWillShow函数和keyboardWillHide函数分别监听了
// UIKeyboardWillShowNotification和UIKeyboardWillHideNotification</p>

<ul>
<li><p>(void) keyboardWillShow:(NSNotification *)notification {
  NSDictionary * info = [notification userInfo];
  CGSize kbSize = [[info objectForKey:UIKeyboardFrameEndUserInfoKey] CGRectValue].size;
  float textViewHeight = UI_SCREEN_HEIGHT - UI_STATUS_BAR_HEIGHT - UI_NAVIGATION_BAR_HEIGHT - UI_TOOL_BAR_HEIGHT - kbSize.height;
  [UIView animateWithDuration:0.3 animations:<sup>{</sup></p>

<pre><code>  _textView.frame = CGRectMake(0, UI_NAVIGATION_BAR_HEIGHT, UI_SCREEN_WIDTH, textViewHeight);
  _toolbar.frame = CGRectMake(0, UI_NAVIGATION_BAR_HEIGHT + textViewHeight, UI_SCREEN_WIDTH, UI_TOOL_BAR_HEIGHT);
</code></pre>

<p>  }];
}</p></li>
<li><p>(void) keyboardWillHide:(NSNotification *)notification {
  CGSize kbSize = CGSizeMake(320, 216);
  float textViewHeight = UI_SCREEN_HEIGHT - UI_STATUS_BAR_HEIGHT - UI_NAVIGATION_BAR_HEIGHT - UI_TOOL_BAR_HEIGHT - kbSize.height;
  [UIView animateWithDuration:0.3 animations:<sup>{</sup></p>

<pre><code>  _textView.frame = CGRectMake(0, UI_NAVIGATION_BAR_HEIGHT, UI_SCREEN_WIDTH, textViewHeight);
  _toolbar.frame = CGRectMake(0, UI_NAVIGATION_BAR_HEIGHT + textViewHeight, UI_SCREEN_WIDTH, UI_TOOL_BAR_HEIGHT);
</code></pre>

<p>  }];
}</p></li>
</ul>


<p>```</p>

<p>可以看到，我将设备的各种高度都定义成了宏，这里的宏UI_SCREEN_HEIGHT表示整个设备的高度，以前这个宏的值是固定的480，现在因为iPhone5中高度值变了，所以我们将这个宏定义改成了如下的值，这样，所有相关的用代码实现的界面位置调整都搞定了。我的UI相关的宏定义如下：</p>

<p>``` objc</p>

<h1>define UI_NAVIGATION_BAR_HEIGHT        44</h1>

<h1>define UI_TOOL_BAR_HEIGHT              44</h1>

<h1>define UI_TAB_BAR_HEIGHT               49</h1>

<h1>define UI_STATUS_BAR_HEIGHT            20</h1>

<h1>define UI_SCREEN_WIDTH                 320</h1>

<p>// 将以下宏定义的值从480改成[[UIScreen mainScreen] bounds].size.height</p>

<h1>define UI_SCREEN_HEIGHT                ([[UIScreen mainScreen] bounds].size.height)</h1>

<p>```</p>

<p>如果你以前没有将这些设备的高度值抽取成宏，我建议你通过查找替换，先将所有用到480的地方修改成宏，然后再增加上面的宏定义即可。</p>

<p>当然，也有一些调整稍微复杂一些，例如粉笔网首页的上拉加载更多，需要判断上拉高度是否到达阈值，这些也是和设备高度相关的。这些阈值信息以前可能就直接写成和高度相关的值，例如220什么的，这些通过直接查找480还没法直接找到。</p>

<p>对于这些问题，只能是通过在模拟器中测试，发现问题，然后再把这些“Magic Number”替换成用上面提到的宏计算的公式。例如我们的上拉加载更多的阈值宏定义如下：</p>

<p>``` cpp</p>

<h1>define LOAD_MORE_TEXT_HEIGHT 77</h1>

<p>// 显示文字阈值</p>

<h1>define LOAD_MORE_THRESHOLD (UI_SCREEN_HEIGHT - UI_STATUS_BAR_HEIGHT - UI_NAVIGATION_BAR_HEIGHT - UI_TAB_BAR_HEIGHT - LOAD_MORE_TEXT_HEIGHT)</h1>

<p>// 刷新阈值</p>

<h1>define LOAD_MORE_MAX       (LOAD_MORE_THRESHOLD + 10.0)</h1>

<p>```</p>

<h4>调整屏幕Rotation的回调函数</h4>

<p>从iOS6开始，苹果修改了屏幕旋转的回调函数。在iOS6以前，回调函数是</p>

<p>``` objc
- (BOOL)shouldAutorotateToInterfaceOrientation:(UIInterfaceOrientation)interfaceOrientation
{</p>

<pre><code>return (interfaceOrientation == UIInterfaceOrientationPortrait);
</code></pre>

<p>}
```</p>

<p>现在新的回调函数是：
``` objc
- (BOOL)shouldAutorotate {</p>

<pre><code>return YES;
</code></pre>

<p>}</p>

<ul>
<li><p>(NSInteger)supportedInterfaceOrientations {
  return UIInterfaceOrientationMaskAllButUpsideDown;
}</p></li>
<li><p>(UIInterfaceOrientation)preferredInterfaceOrientationForPresentation {
  return UIInterfaceOrientationPortrait;
}
```</p></li>
</ul>


<p>并且，现在是否旋转屏幕是由最上层的View Controller决定。例如，如果你是由 UITabBarController或UINavigationController包起来的界面的话，是否旋转屏幕就由UITabBarController或UINavigationController中的shouldAutorotate回调决定，而默认其返回的是YES。修改方法是给这2个容器Controller增加Addition,将其shouldAutorotate修改成由当前显示的子view controller决定，或者直接默认返回NO。</p>

<h4>提交应用</h4>

<p>基本上就是以上这些调整工作了，完了之后用Xcode4.5编译后提交审核，并且在itunes connect中设置iPhone5屏幕尺寸的app介绍截图即可。业界传言说对于支持iPhone5的程序，苹果在应用审核的时候会优先进行，我不知道是否是真的，不过我们的应用确实只用了5天时间就通过了审核，这是我个人遇到过的最快的一次审核。</p>

<p>祝大家国庆节玩得开心～</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[用脚本来简化iOS美术同学的工作]]></title>
    <link href="http://blog.devtang.com/blog/2012/08/26/use-script-to-power-up-ui-work/"/>
    <updated>2012-08-26T20:34:00+08:00</updated>
    <id>http://blog.devtang.com/blog/2012/08/26/use-script-to-power-up-ui-work</id>
    <content type="html"><![CDATA[<h2>问题</h2>

<p>我们知道，在iOS开发中，为了使我们的app能够同时支持iPhone的Retina屏幕和普通屏幕，美术同学需要对UI设计稿中的每个元素进行2次切图。苹果要求对图片元素的命名分别为 name.png 和 name@2x.png，带@2x的表示是Retina屏幕的贴图，不带@2x的同名文件为普通屏幕的贴图。</p>

<p>我在开发的时候发现很难要求美术同学按照开发的要求来对图片命名。她们通常对于切图的命名是例如 <em>登录按钮大.png</em> ，<em>登录按钮小.png</em>, <em>登录按钮按下大.png</em> <em>登录按钮按下小.png</em> 这样的形式。于是，对这些文件按照苹果的要求进行重命名就成了我这个码农的一个体力活。</p>

<!-- more -->


<h2>解决方案</h2>

<p>有什么方法能减少开发和美术的体力活呢？想到因为 name@2x.png 的图片是 name.png 图片的2整倍，所以，我们完全可以让美术只切@2x的大图，而我们使用脚本来生成小图。于是我写了下面这样的一个脚本，我只需要将所有的大图按照类似 name-1@2x.png , name-2@2x.png 方式命名，然后脚本就会自动帮我生成对应的名为 name-1.png 和 name-2.png的小图。</p>

<p>``` objc</p>

<h1>! /bin/bash</h1>

<h1>File name : convertImage.sh</h1>

<h1>Author: Tang Qiao</h1>

<h1></h1>

<h1>print usage</h1>

<p>usage() {</p>

<pre><code>cat &lt;&lt; EOF
Usage:
    convertImage.sh &lt;src directory&gt; &lt;dest directory&gt;
</code></pre>

<p>EOF
}</p>

<p>if [ $# -ne 2 ]; then</p>

<pre><code>usage
exit 1
</code></pre>

<p>fi</p>

<p>SRC_DIR=$1
DEST_DIR=$2</p>

<h1>check src dir</h1>

<p>if [ ! -d $SRC_DIR ]; then</p>

<pre><code>echo "src directory not exist: $SRC_DIR"
exit 1
</code></pre>

<p>fi</p>

<h1>check dest dir</h1>

<p>if [ ! -d $DEST_DIR ]; then</p>

<pre><code>mkdir -p $DEST_DIR
</code></pre>

<p>fi</p>

<p>for src_file in $SRC_DIR/<em>.</em> ; do</p>

<pre><code>echo "process file name: $src_file"
# 获得去掉文件名的纯路径
src_path=`dirname $src_file`
# 获得去掉路径的纯文件名
filename=`basename $src_file`
# 获得文件名字(不包括扩展名)
name=`echo "$filename" | cut -d'.' -f1`
# remove @2x in filename if there is
name=`echo "$name" | cut -d"@" -f1`
# 获得文件扩展名
extension=`echo "$filename" | cut -d'.' -f2`
dest_file="$DEST_DIR/${name}.${extension}"

convert $src_file -resize 50% $dest_file
</code></pre>

<p>done
```</p>

<p>脚本使用方法：将以上代码另存为 convertImage.sh，然后用以下方式调用此脚本，即可将源文件夹中所有以@2x结尾的图片文件转成一半大小的、去掉@2x的小图片。</p>

<p><code>bash
convertImage.sh 源文件夹 目标文件夹
</code></p>

<p>使用以上脚本后，美术只用切一半的图了。因为给我的切图少了，所以我可以更加方便地找到对应的切图了。另外，我也减少了一半对切图进行重命名的工作。</p>

<h2>Tips</h2>

<h3>imagemagick</h3>

<p>如果你运行以上脚本失败，请先用brew 或 port安装 imagemagick。imagemagick是一个相当强大的图象处理库。
<code>bash
brew install imagemagick
</code></p>

<h3>检查图片</h3>

<p>在使用该脚本一段时间后，我发现美术同学给我的大图的长宽常常不是偶数，这样造成缩小的图就不是原图的整倍数了。为了方便我检查美术给我的图片是否宽高都是偶数，我写了如下检查的脚本，这样就可以检查图片的宽高是否符合要求了。</p>

<p>``` bash</p>

<h1>! /bin/bash</h1>

<h1>File name : checkImageSize.sh</h1>

<h1>Author: Tang Qiao</h1>

<h1></h1>

<p>usage() {</p>

<pre><code>cat &lt;&lt;EOF
Usage:
    checkImageSize.sh &lt;directory&gt;
</code></pre>

<p>EOF
}</p>

<p>if [ $# -ne 1 ]; then</p>

<pre><code>usage
exit 1
</code></pre>

<p>fi</p>

<p>SRC_DIR=$1</p>

<h1>check src dir</h1>

<p>if [ ! -d $SRC_DIR ]; then</p>

<pre><code>echo "src directory not exist: $SRC_DIR"
exit 1
</code></pre>

<p>fi</p>

<p>for src_file in $SRC_DIR/*.png ; do</p>

<pre><code>echo "process file name: $src_file"
width=`identify -format "%[fx:w]" $src_file`
height=`identify -format "%[fx:h]" $src_file`
# check width
modValue=`awk -v a=$width 'BEGIN{printf "%d", a % 2}'`
if [ "$modValue" == "1" ]; then
   echo "[Error], the file $src_file width is $width" 
fi
# check height
modValue=`awk -v a=$height 'BEGIN{printf "%d", a % 2}'`
if [ "$modValue" == "1" ]; then
   echo "[Error], the file $src_file height is $height" 
fi
</code></pre>

<p>done
```</p>

<h3>问题</h3>

<p>我在使用以上方法时，发现由于imagemagick压缩比太高，生成的图片如果象素太小，它就会生成索引图片，而不知道何故，少量索引图片在iPhone 3GS上会显示出一条黑线在图片底部。对于这些图片，用photoshop将其模式改成RGB颜色即可。如下所示：</p>

<p><img src="/images/ui-script-tips.png" title="" ></p>

<p>用脚本代替体力活是一件很happy的事情，因为你可以用省下来的时间多做一些有意思的事情了。</p>

<p>Have fun !</p>

<h3>后记</h3>

<p>在发表完这篇文章后，得到了很多反馈。</p>

<p>其中<a href="http://weibo.com/wangyihan01">李祎</a>同学提到了一个iOS独立开发者的解决思路：<a href="http://kevincao.com/2011/08/prepare-png-for-iphone-app/">http://kevincao.com/2011/08/prepare-png-for-iphone-app/</a> ，我感觉该博客中提到的方法，或许更加适合美术同学，因为整个操作都是图形化的。所以附在这里，希望对大家有用。</p>

<p>另外，网易杭研院的<a href="http://weibo.com/myerlang">施强</a>同学推荐了一个用于缩图的软件:<a href="http://www.xnconvert.com/">http://www.xnconvert.com/</a> ，据说也能很好的解决以上问题。一并在此推荐给大家作为参考。</p>
]]></content>
  </entry>
  
</feed>
