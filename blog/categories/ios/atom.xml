<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: iOS | 唐巧的技术博客]]></title>
  <link href="http://blog.devtang.com/blog/categories/ios/atom.xml" rel="self"/>
  <link href="http://blog.devtang.com/"/>
  <updated>2012-11-17T12:00:11+08:00</updated>
  <id>http://blog.devtang.com/</id>
  <author>
    <name><![CDATA[唐巧]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[放弃iOS4，拥抱iOS5]]></title>
    <link href="http://blog.devtang.com/blog/2012/11/16/drop-ios4-enbrace-ios5/"/>
    <updated>2012-11-16T20:47:00+08:00</updated>
    <id>http://blog.devtang.com/blog/2012/11/16/drop-ios4-enbrace-ios5</id>
    <content type="html"><![CDATA[<p><img src="/images/ios5.jpg"></p>

<h2>前言</h2>

<p>苹果在2011年的WWDC大会上发布了iOS5，不过考虑到要支持iOS4.x的系统，大多数App都无法使用iOS5的新特性。现在将近1年半过去了，从我们自己的App后台的统计数据、一些第三方的统计数据和一些业界的朋友告知我的数据都显示，iOS4.x的系统所占比例已经小于5%了，并且还在持续下降。所以，我们有必要放弃对iOS4.x的支持，全面拥抱iOS5。</p>

<p>只支持iOS5.0以上版本使得我们可以使用iOS5带来的诸多新特性，有些新特性可以极大地方便我们的开发，我将这些新特性列举如下。</p>

<!-- more -->


<h2>Storyboard</h2>

<p>Storyboard（故事板）是XCode4和iOS5提供的一个用于控制View Controller之间跳转关系的新概念。你可以把它理解成以前一堆Nib文件的集合。在这个集合里面，每个Nib文件被称作scene（场景），scene之间的跳转关系被称作segue。segue代表着传统的界面间切换的方式，通常是Push方式和Modal方式，当然，你也可以自定义自己的Segue。如下示例图是一个Storyboard的界面：</p>

<p><img src="/images/enbrace-ios5-1.png"></p>

<p>使用Storyboard的好处有以下几点：</p>

<ol>
<li>你可以从storyboard中很方便地梳理出所有View Controller的界面间的调用关系。比如上面那个storyboard示例图，我们就可以很清楚地了解到4个View Controller相互之间是怎么调用的。而这在以前，这些调用关系，都是隐藏在每个View Controller的代码中的，你需要一点一点读代码，才可以将整个调用逻辑整理清楚。</li>
<li>使用Storyboard可以使用Table View Controller的Static Cell功能。简单来说，对于象设置页面等固定内容的TableView，可以直接在Storyboard中通过拖拽就可以设置其界面了，而不是象以前那样需要写一堆table view的delegate和data source回调函数。</li>
<li>通过实现 - (void)prepareForSegue:(UIStoryboardSegue *)segue sender:(id)sender 方法，每个View Controller的跳转逻辑都聚集在一处，这方便我们统一管理界面跳转和传递数据，这相当于多了一个编程约定。</li>
<li>Storyboard可以方便将一些常用功能模块化和复用。例如WWDC2011年介绍Storyboard的视频就将微博分享功能模块化成一个单独的Storyboard。我在开发App时，也将例如通过第三方注册登录模块做成一个单独的Storyboard，便于以后复用。</li>
</ol>


<p>另外，在iOS6中，storyboard又新增了如exit segue, container view等新功能，这些功能都非常体贴，我们向新的技术方案迁移可以在未来更加方便地使用iOS和XCode的新特性，方便我们的开发。</p>

<p>当然，Storyboard也有它的问题。比如，如果2个人同时编译storyboard，在版本管理中出现冲突时会比较麻烦。虽然storyboard是XML格式的，但是里面的信息有些时候还是不太清晰，当冲突发生时，合并冲突可能会比较麻烦。解决办法是，将Storyboard按功能拆分，每个人尽量负责一个单独的Storyboard，如果实在需要2个人都修改它，避免同时修改。</p>

<h2>ARC</h2>

<p>因为ARC是在编译期做的，所以虽然是与iOS5.0同时推出的Objective-C特性，但是其实ARC是支持iOS4的。只是在iOS4中，不能使用ARC的weak关键字。</p>

<p>由于不需要支持iOS4，我们可以将原本的 __unsafe_unretained 关键字换成weak。这样当这个弱引用对象被回收时，weak指针会被智能地设置成nil，防止“野指针”的产生。</p>

<p>很多人说ARC有这样那样的问题，其实他们是没有真正用好ARC。我在开发粉笔网iPhone客户端时，由于使用了ARC，花三个月开发完的应用，用instruments检测后，没有发现任何内存泄漏问题。这在没有使用ARC的工程中是不可想象的。苹果在推出ARC两年后，今年正式将ARC引入到Mac OS操作系统的SDK中，并且正式将原有的GC deprecated掉，这也说明了ARC技术方案已经是非常成熟的了。</p>

<h2>UIKit</h2>

<p>UIKit在iOS5进行了大量更新。除了新增了如UIStepper控件外，也为以前的控件增加了更多的定制接口。我们可以方便地定义UINavigationBar, UITabBar, UIToolBar等常用控件。</p>

<p>苹果在iOS5中给UIViewController新增加的5方法以及一个属性。关于这个新特性我在<a href="http://blog.devtang.com/blog/2012/02/06/new-methods-in-uiviewcontroller-of-ios5/">这篇文章</a>中详细介绍过。新增的方法主要解决的是让 view的load/unLoad/appear/disappear的相关回调可以传递到子view controller中。</p>

<h2>CoreImage</h2>

<p>苹果从iOS5开始，引入了新的图象类CIImage。CIImage相比以前的UIImage类，更加适合于图象处理和图象分析。</p>

<p>在图象处理方法，苹果内置了CIFilter类，方便开发者对图形进行各种各样的特效处理，在iOS5中，苹果提供了48种Filter，而在iOS6中，内置的Filter达到了93种。可以使用如下代码，查询到当前系统中提供的Filter列表：</p>

<p>``` objc
- (void)logAllFilters {</p>

<pre><code>NSArray * properties = [CIFilter filterNamesInCategory:kCICategoryBuiltIn];
NSLog(@"%@", properties);
for (NSString * filterName in properties) {
    CIFilter * fltr = [CIFilter filterWithName:filterName];
    NSLog(@"%@", [fltr attributes]);
}
</code></pre>

<p>}
```</p>

<p>这些内置的Filter在分类上，包括：</p>

<ol>
<li>颜色效果类。例如黄昏效果，曝光度调整等。</li>
<li>组合效果类。把2张图片按各种规则混合成一张图。</li>
<li>几何变形类。例如把照片倾斜或者翻转。</li>
<li>重复效果类。如平铺，折叠，镜象等。</li>
<li>失真扭曲类。如把图片中心做成漩涡效果等。</li>
<li>模糊和锐化类。</li>
<li>Stylize效果。</li>
<li>Halftone效果。</li>
</ol>


<p>以上所有效果可以叠加作用在一起，最终你可以创造出自己的图片处理效果。最终你可以通过CIContext，将处理过的CIImage转换成UIImage输出。有了Core Image，你可以方便地开发图象处理相关的应用，而不用关心图象处理算法的细节。</p>

<h2>NSJSONSerialization</h2>

<p>在我的<a href="http://blog.devtang.com/blog/2012/05/05/do-not-use-sbjson/">《不要使用SBJSON(json-framework)》</a> 一文中，我提到了关于JSON解析库的性能测试。测试结果表明，苹果从iOS5开始提供的 <a href="http://developer.apple.com/library/ios/#documentation/Foundation/Reference/NSJSONSerialization_Class/Reference/Reference.html#//apple_ref/doc/uid/TP40010946">NSJSONSerialization</a> 类有着最好的性能表现。所以，从iOS5以后，你可以扔掉那些第三方JSON解析库了。</p>

<h2>ViewController切换</h2>

<p>iOS提供了如下新的接口来切换ViewController，而以前的presentModalViewController和dismissModalViewControllerAnimated被Deprecated掉了。</p>

<p>``` objc
// 新的接口
- (void)presentViewController:(UIViewController *)viewControllerToPresent animated: (BOOL)flag completion:(void (<sup>)(void))completion;</sup>
- (void)dismissViewControllerAnimated: (BOOL)flag completion: (void (<sup>)(void))completion;</sup></p>

<p>// 被Deprecated的接口
- (void)presentModalViewController:(UIViewController *)modalViewController animated:(BOOL)animated;
- (void)dismissModalViewControllerAnimated:(BOOL)animated;
```</p>

<p>新接口的差别是提供了一个completion参数，允许你传入一个block，来定义该操作结束时的回调。使用新的函数后，可以方便同时Dismiss或Present多个View Controller，也可以方便做多个UI效果之间的衔接。</p>

<h2>其它</h2>

<p>GameKit, Core Data, NewsstandKit, GLKit在iOS5中都有更新。可惜我都没有具体使用过，所以不便做更多介绍。</p>

<p>Have fun!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[让XCode的 stack trace信息可读]]></title>
    <link href="http://blog.devtang.com/blog/2012/11/14/make-stack-trace-more-readable/"/>
    <updated>2012-11-14T20:19:00+08:00</updated>
    <id>http://blog.devtang.com/blog/2012/11/14/make-stack-trace-more-readable</id>
    <content type="html"><![CDATA[<p>昨天在写iOS代码的时候，调试的时候模拟器崩溃了。异常停在了如下整个main函数的入口处：</p>

<p>``` objc
int main(int argc, char *argv[])
{</p>

<pre><code>@autoreleasepool {
    // 异常停在了下面这行，毫无提示作用
    return UIApplicationMain(argc, argv, nil, NSStringFromClass([MyClass class]));
}
</code></pre>

<p>}</p>

<p>```</p>

<!-- more -->


<p>XCode的Console界面报出了一些出错信息, 如下图所示：</p>

<p><img src="/images/stacktrace-1.jpg"></p>

<p>我根据Console里面的文字提示信息，猜出应该是出现了空指针nil的操作。但是具体出错在哪一行，却不知道。最终虽然找到了bug，但是debug的过程确实费了些时间。考虑到这个stace trace信息应该对我挺有帮助才对的，所以我就查了一下如何让这原本一堆16进制的调用栈信息更可读。于是在stackoverflow上找到了2个比较好的解决办法，在这里分享给大家。</p>

<h2>方法一</h2>

<p>该<a href="http://stackoverflow.com/questions/7841610/xcode-4-2-debug-doesnt-symbolicate-stack-call">方法</a>的步骤是，首先在你的AppDelegate中定义一个方法, 用于处理异常：</p>

<p>``` objc
void uncaughtExceptionHandler(NSException *exception) {</p>

<pre><code>NSLog(@"CRASH: %@", exception);
NSLog(@"Stack Trace: %@", [exception callStackSymbols]);
// Internal error reporting
</code></pre>

<p>}
```
然后在应用启动时，设置这个方法作为自己的自定义异常回调：</p>

<p>``` objc
- (BOOL)application:(UIApplication <em>)application didFinishLaunchingWithOptions:(NSDictionary </em>)launchOptions
{</p>

<pre><code>NSSetUncaughtExceptionHandler(&amp;uncaughtExceptionHandler);
// Normal launch stuff
</code></pre>

<p>}
```</p>

<p>完成之后，当对于上面的异常，在定义了这个回调之后，Log信息变成如下所示，出错行一目了然，根据下面的可读的stack trace，我一下就可以找到是QuestionParser这个类的第378行导致的异常，进而可以跳到出错行分析原因，很容易就把bug修复了。</p>

<p>``` objc
Ape[2711:11303] CRASH: *** -[__NSPlaceholderDictionary initWithObjects:forKeys:count:]: attempt to insert nil object from objects[2]
Ape[2711:11303] Stack Trace: (</p>

<pre><code>0   CoreFoundation                      0x0209402e __exceptionPreprocess + 206
1   libobjc.A.dylib                     0x01a71e7e objc_exception_throw + 44
2   CoreFoundation                      0x0205aa95 -[__NSPlaceholderDictionary initWithObjects:forKeys:count:] + 165
3   CoreFoundation                      0x020874e9 +[NSDictionary dictionaryWithObjects:forKeys:count:] + 73
4   Ape                                 0x00096a0a +[QuestionParser parseToDictionary:] + 378
5   Ape                                 0x00096434 -[QuestionStore putQuestion:] + 308
6   Ape                                 0x00089ddf -[QuestionViewController requestFinished:] + 303
7   Ape                                 0x000869dd -[NetworkAgent requestFinished:] + 653
8   Ape                                 0x00085d33 __27-[NetworkAgent addRequest:]_block_invoke_0 + 131
9   libdispatch.dylib                   0x01cf153f _dispatch_call_block_and_release + 15
10  libdispatch.dylib                   0x01d03014 _dispatch_client_callout + 14
11  libdispatch.dylib                   0x01cf2fd6 _dispatch_after_timer_callback + 28
12  libdispatch.dylib                   0x01d03014 _dispatch_client_callout + 14
13  libdispatch.dylib                   0x01cfa8b7 _dispatch_source_latch_and_call + 219
14  libdispatch.dylib                   0x01cf6405 _dispatch_source_invoke + 322
15  libdispatch.dylib                   0x01cf3768 _dispatch_main_queue_callback_4CF + 187
16  CoreFoundation                      0x0203aaf5 __CFRunLoopRun + 1925
17  CoreFoundation                      0x02039f44 CFRunLoopRunSpecific + 276
18  CoreFoundation                      0x02039e1b CFRunLoopRunInMode + 123
19  GraphicsServices                    0x0282b7e3 GSEventRunModal + 88
20  GraphicsServices                    0x0282b668 GSEventRun + 104
21  UIKit                               0x00be265c UIApplicationMain + 1211
22  Ape                                 0x00016c5d main + 141
23  Ape                                 0x00002b05 start + 53
24  ???                                 0x00000001 0x0 + 1
</code></pre>

<p>)</p>

<p>```</p>

<h2>方法二</h2>

<p>方法二相比方法一更加简单，具体做法是在XCode界面中按cmd + 6跳到Breakpoint的tab，然后点击左下角的+号，增加一个Exception的断点，如下图所示。这样，当异常出现时，会自动停在异常处，而不会抛出到UIApplicationMain。拿我的有bug的程序来说，代码会自动断在QuestionParser这个类的第378行。</p>

<p><img src="/images/stacktrace-2.png"></p>

<h2>总结</h2>

<p>其实以前XCode是能显示出可读的stack trace信息的，似乎到了XCode4.2以后就出问题了。所以上面提到的2个办法相当于walk around解决了XCode4.2以后出现的bug。如果该文章对你有用，希望你能帮我点击下面的分享按钮，分享给更多朋友，同时也帮我宣传一下博客，这将有助于我分享更多的心得给大家，Have fun!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[改进iOS客户端的升级提醒功能]]></title>
    <link href="http://blog.devtang.com/blog/2012/11/10/how-to-design-upgrade-notice/"/>
    <updated>2012-11-10T18:42:00+08:00</updated>
    <id>http://blog.devtang.com/blog/2012/11/10/how-to-design-upgrade-notice</id>
    <content type="html"><![CDATA[<h2>功能设计</h2>

<p>先申明一下，我是码农，不是一个产品经理，但我觉得现有市面上的很多App，在设计“升级提示功能”都有问题。在此分享一下我的想法，欢迎大家讨论。</p>

<p>这些有问题的App包括：新浪微博、网易微博、网易新闻客户端以及大部分带有升级提示功能的App，所以我觉得这个问题还是挺普遍的。对于该问题，一句话描述起来就是：“这些App都会在用户刚刚使用它的时候，提示有新版本，让用户去AppStore上下载最新的版本”。下面是某个应用的升级提示截图：</p>

<p><img src="/images/app-upgrade-1.png"></p>

<p>为什么我认为这是一个糟糕的设计呢？因为用户刚刚打开你的App，明显就是想使用你的功能。例如刚刚打开新浪微博，可能就是想看一下最新的消息或回复。刚刚打开网易新闻客户端，可能就是想看看最新的新闻。这个时候，你告诉用户有新版本，是想让用户暂时放弃使用该App吗？我不知道有多少用户会去点“升级”这个按钮，反正我每次看到这个提示都很郁闷，因为我如果点了，我就暂时不能使用该应用了（升级时原版本的App是无法使用的）。所以我在想，这个提示升级的时间能不能做得更友好一些？</p>

<!-- more -->


<p>有一次在地铁上我想到了一个好办法，就是让升级提示不是出现在软件刚刚打开的时候，而是用户刚刚退出App的时候，我们可以在用户刚刚退出App的时候，向iOS设备发一个本地的通知(Local Notification)，在本地通知上显示升级提示。当用户点击这个升级提示时，我们的App在启动后跳转到AppStore，这样就达到的提示升级的效果。</p>

<p>这样做相比以前的好处有以下几点：</p>

<ol>
<li>用户退出App的时刻，是一个访问这个App活动的结束。在这个时候提示，用户更有理由接受升级。</li>
<li>即便用户当前不接受升级，但这个升级提示都会存在用户的通知中心中，用户想升级时，点击这个通知，就可以方便地一键跳到AppStore的下载页面。而之前的方法在用户取消后，用户就不方便取获下载地址了。</li>
</ol>


<p>另外，本地通知的使用只需要iOS4.0以上版本即可，而在中国，<a href="http://www.zhihu.com/question/20267080">iOS4.0以上比例</a>达到了99%。本地通知也不需要向用户申请发送通知的DeviceToken，所以该方案很少被用户禁止（用户只能专门去通知中心将该应用的所有通知关闭）。当然，这个升级提示也不应该每次都出现，以免对用户产生太多打挠，象我在粉笔网客户端上设置的策略是最多半个月出现一次。</p>

<p>在我在粉笔网iPhone端实现该方案后，有一次我发现支付宝的iOS客户端也采用通知的方式来提示用户升级，看来大家都想到一块儿了。不过从通知的发送时间来看，他们应该不是使用的本地通知，而是通过服务器发送Push通知的方式。这种方式的好处是即使用户安装后一次也没有使用你的App，你还是可以通过通知来唤醒他，可能的坏处是：</p>

<ol>
<li>可能用户已经升完级了，你还把升级通知的信息发给用户了。象我就是，支付宝都升完级了，还发通知提示我有新版可以使用。</li>
<li>用户如果禁止了应用的Push通知，你就没办法发送升级提醒了。</li>
</ol>


<h2>技术实现</h2>

<p>再简单说一下技术实现，我写了一个VersionAgent类，每24小时最多向服务器请求一次最新的App版本，如果版本有更新，则在AppDelegate的applicationDidEnterBackgroundl回调中，发送一个本地通知，示例代码如下：</p>

<p>``` objc
- (void)applicationDidEnterBackground:(UIApplication *)application
{</p>

<pre><code>if ([[VersionAgent sharedInstance] shouldShowLocalNotification]) {
    dispatch_async(dispatch_get_main_queue(), ^{
        UILocalNotification * localNotification = [[UILocalNotification alloc] init];
        if (localNotification) {
            localNotification.fireDate= [[[NSDate alloc] init] dateByAddingTimeInterval:3];
            localNotification.timeZone=[NSTimeZone defaultTimeZone];
            localNotification.alertBody = @"粉笔网客户端有新的版本，点击到App Store升级。";
            localNotification.alertAction = @"升级";
            localNotification.soundName = @"";
            [application scheduleLocalNotification:localNotification];
        }
    });
}
</code></pre>

<p>}
```</p>

<p>然后通过AppDelegate的回调函数，判断App的启动方式是否是通过用户点击通知中心的升级提示来启动，如果是，则跳转到AppStore，示例代码如下：
``` objc
- (void)application:(UIApplication <em>)application didReceiveLocalNotification:(UILocalNotification </em>)notification {</p>

<pre><code>// open app store link
NSString * url = [NSString stringWithFormat:@"itms-apps://itunes.apple.com/app/id%@", APP_STORE_ID];
[[UIApplication sharedApplication] openURL:[NSURL URLWithString:url]];
</code></pre>

<p>}</p>

<p>```</p>

<h2>题外话</h2>

<p><img src="/images/app-upgrade-2.jpeg"></p>

<p>最新微博上有一个<a href="http://www.chinanews.com/sh/2012/11-09/4315347.shtml?utm_source=bshare&amp;utm_campaign=bshare&amp;utm_medium=sinaminiblog#bsh-24-154760667">新闻</a>很火，一个技术男，给女友发弹窗通知求爱。有些人回复说这样做太麻烦，需要在服务器上记DeviceToken，否则所有用户都发的话，会让很多不相关的人收到。</p>

<p>其实这完全可以用本地通知来做，完全不需要服务器配合，相当简单。
具体做法是：你自己写一个发本地求爱通知的小应用，然后记下女友手机的UDID，将女友的手机设置成开发者设备，然后抓住一次机会在其手机上安装好开发者证书和你写的这个小App即可。可以把这个App隐藏在某个文件夹下面，然后打开一次，设置好本地通知的发出时间即可。</p>

<p>我的很多文章最后结尾都是Have fun，不过最近很难高兴起来啊。因为0x12 Big，今天google的全线产品都无法访问了。想起我每天的工作都是用google搜技术贴，用gmail收邮件，用gtalk聊天，我的联系人信息，备忘录也是同步在google contact上，我真的无法fun起来了。本博客是架设在github上的，我也很担心该博客可能也会因为是境外IP而被禁止访问。</p>

<p>有时候，我很气愤，而有时候，我会乐观地想，这些都是负能量的积累，黎明前的黑暗。不管怎么样，谁也无法阻止大家对自由的向往，希望有朝一日，所有人都能自由地获取信息。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在MacOS和iOS系统中使用OpenCV]]></title>
    <link href="http://blog.devtang.com/blog/2012/10/27/use-opencv-in-ios/"/>
    <updated>2012-10-27T20:43:00+08:00</updated>
    <id>http://blog.devtang.com/blog/2012/10/27/use-opencv-in-ios</id>
    <content type="html"><![CDATA[<h2>前言</h2>

<p><img src="/images/opencv.png"></p>

<p><a href="http://opencv.org/about.html">OpenCV</a> 是一个开源的跨平台计算机视觉库，实现了图像处理和计算机视觉方面的很多通用算法。</p>

<p>最近试着在MacOS和iOS上使用OpenCV，发现网上关于在MacOS和iOS上搭建OpenCV的资料很少。好不容易搜到些资料，却发现由于OpenCV和XCode的版本更新，变得不再有用了。有些问题费了我很多时间，在此总结分享给大家，希望后来人少走些弯路。</p>

<p>可以预见到，随着XCode和OpenCV的版本更新，本文可能不再有效了。所以特此注明，文本介绍的搭建方法仅针对于 XCode4.5.1 和 OpenCV 2.4.2版本。</p>

<!-- more -->


<h2>MacOS系统中使用OpenCV</h2>

<h3>安装OpenCV</h3>

<p>相信大部分Mac用户都安装了brew或port，如果你没有装，那么首先安装一下brew吧。使用如下命令安装brew:</p>

<p><code>bash
ruby -e "$(curl -fsSkL raw.github.com/mxcl/homebrew/go)"
</code></p>

<p>在安装好brew后，只需要一条命令就可以安装OpenCV了：
<code>bash
brew install opencv
</code></p>

<p>通常情况下这样做就应该会安装成功，但我在公司和家里面的电脑尝试的时候，brew都会报一些错误，我遇到的都是一些小问题，按照brew的提示信息，解决掉相应的问题即可。</p>

<p>安装成功后，你应该可以在“/usr/local/include"目录下找到名为opencv和opencv2的目录，这里面是OpenCV相关的头文件。你也可以在“/usr/local/lib"目录下找到许多以libopencv_开头的.dylib文件，这些是OpenCV的链接库文件。</p>

<h3>在MacOS系统中使用OpenCV</h3>

<p>接着我们可以试着在Xcode工程中使用OpenCV。</p>

<p>新建一个Cocoa Application的工程。工程建好后，选中工程的Target，在Build Settings一样，找到“Header Search Paths"这一个选项，将它的值改为“/usr/local/include"。如下所示：</p>

<p><img src="/images/use-opencv-in-mac-1.png"></p>

<p>接着切换到Build Phases这个tab，在“Link Binary With Libraries"中，选项+号，然后将弹出的文件选择对话框目录切换到“/usr/local/lib"目录下，选择你需要使用的OpenCV链接库（通常情况下，你至少会需要core、highgui和imgproc库)，如下图所示：</p>

<p><img src="/images/use-opencv-in-mac-2.png"></p>

<p>这里有一个技巧，因为 /usr 目录在对话框中默认不是可见的，可以按快捷键 command + shift + G，在弹出的“前往文件夹"对话框中输入 /usr/local/lib ，即可跳转到目标文件夹。如下图所示：</p>

<p><img src="/images/use-opencv-in-mac-3.png"></p>

<p>下一步是我自己试出来的，你需要在Build Settings中，将“C++ Language Dialect”设置成C++11，将“C++ Standard Library”设置成libstdc++ ，如下图所示。个人感觉是由于XCode默认设置的GNU++11、libc++与OpenCV库有一些兼容性问题，我在更改该设置前老是出现编译错误。如果后续版本解决了这个问题，就不用进行这一步了。</p>

<p><img src="/images/use-opencv-in-mac-4.png"></p>

<p>把上面的设置都做好后，就可以在需要的使用OpenCV库的地方，加上opencv的头文件引用即可：</p>

<p>``` objc</p>

<h1>import "opencv2/opencv.hpp"</h1>

<p>```</p>

<p>注意，如果你的源文件扩展名是.m的，你还需要改成.mm，这样编译器才知道你将会在该文件混合使用C++语言和Objective-C语言。</p>

<p>OpenCV处理图象需要的格式是cv::Mat类，而MacOS的图象格式默认是NSImage，所以你需要知道如何在cv::Mat与NSImage之前相互转换。如下是一个NSImage的Addition，你肯定会需要它的。该代码来自stackoverflow上的<a href="http://stackoverflow.com/questions/8563356/nsimage-to-cvmat-and-vice-versa">这个贴子</a>。</p>

<p>NSImage+OpenCV.h 文件：
``` objc
//
//  NSImage+OpenCV.h
//
//  Created by TangQiao on 12-10-26.
//</p>

<h1>import &lt;Foundation/Foundation.h></h1>

<h1>import "opencv2/opencv.hpp"</h1>

<p>@interface NSImage (OpenCV)</p>

<p>+(NSImage*)imageWithCVMat:(const cv::Mat&amp;)cvMat;
-(id)initWithCVMat:(const cv::Mat&amp;)cvMat;</p>

<p>@property(nonatomic, readonly) cv::Mat CVMat;
@property(nonatomic, readonly) cv::Mat CVGrayscaleMat;</p>

<p>@end</p>

<p>```</p>

<p>NSImage+OpenCV.mm文件：
``` objc
//
//  NSImage+OpenCV.mm
//
//  Created by TangQiao on 12-10-26.
//</p>

<h1>import "NSImage+OpenCV.h"</h1>

<p>static void ProviderReleaseDataNOP(void <em>info, const void </em>data, size_t size)
{</p>

<pre><code>return;
</code></pre>

<p>}</p>

<p>@implementation NSImage (OpenCV)</p>

<p>-(CGImageRef)CGImage
{</p>

<pre><code>CGContextRef bitmapCtx = CGBitmapContextCreate(NULL/*data - pass NULL to let CG allocate the memory*/,
                                               [self size].width,
                                               [self size].height,
                                               8 /*bitsPerComponent*/,
                                               0 /*bytesPerRow - CG will calculate it for you if it's allocating the data.  This might get padded out a bit for better alignment*/,
                                               [[NSColorSpace genericRGBColorSpace] CGColorSpace],
                                               kCGBitmapByteOrder32Host|kCGImageAlphaPremultipliedFirst);

[NSGraphicsContext saveGraphicsState];
[NSGraphicsContext setCurrentContext:[NSGraphicsContext graphicsContextWithGraphicsPort:bitmapCtx flipped:NO]];
[self drawInRect:NSMakeRect(0,0, [self size].width, [self size].height) fromRect:NSZeroRect operation:NSCompositeCopy fraction:1.0];
[NSGraphicsContext restoreGraphicsState];

CGImageRef cgImage = CGBitmapContextCreateImage(bitmapCtx);
CGContextRelease(bitmapCtx);

return cgImage;
</code></pre>

<p>}</p>

<p>-(cv::Mat)CVMat
{</p>

<pre><code>CGImageRef imageRef = [self CGImage];
CGColorSpaceRef colorSpace = CGImageGetColorSpace(imageRef);
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;
cv::Mat cvMat(rows, cols, CV_8UC4); // 8 bits per component, 4 channels

CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNoneSkipLast |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), imageRef);
CGContextRelease(contextRef);
CGImageRelease(imageRef);
return cvMat;
</code></pre>

<p>}</p>

<p>-(cv::Mat)CVGrayscaleMat
{</p>

<pre><code>CGImageRef imageRef = [self CGImage];
CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceGray();
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;
cv::Mat cvMat = cv::Mat(rows, cols, CV_8UC1); // 8 bits per component, 1 channel
CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNone |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), imageRef);
CGContextRelease(contextRef);
CGColorSpaceRelease(colorSpace);
CGImageRelease(imageRef);
return cvMat;
</code></pre>

<p>}</p>

<ul>
<li><p>(NSImage *)imageWithCVMat:(const cv::Mat&amp;)cvMat
{
  return [[[NSImage alloc] initWithCVMat:cvMat] autorelease];
}</p></li>
<li><p>(id)initWithCVMat:(const cv::Mat&amp;)cvMat
{
  NSData *data = [NSData dataWithBytes:cvMat.data length:cvMat.elemSize() * cvMat.total()];</p>

<p>  CGColorSpaceRef colorSpace;</p>

<p>  if (cvMat.elemSize() == 1)
  {</p>

<pre><code>  colorSpace = CGColorSpaceCreateDeviceGray();
</code></pre>

  }
  else
  {

<pre><code>  colorSpace = CGColorSpaceCreateDeviceRGB();
</code></pre>

<p>  }</p>

<p>  CGDataProviderRef provider = CGDataProviderCreateWithCFData((CFDataRef)data);</p>

<p>  CGImageRef imageRef = CGImageCreate(cvMat.cols,                                     // Width</p>

<pre><code>                                  cvMat.rows,                                     // Height
                                  8,                                              // Bits per component
                                  8 * cvMat.elemSize(),                           // Bits per pixel
                                  cvMat.step[0],                                  // Bytes per row
                                  colorSpace,                                     // Colorspace
                                  kCGImageAlphaNone | kCGBitmapByteOrderDefault,  // Bitmap info flags
                                  provider,                                       // CGDataProviderRef
                                  NULL,                                           // Decode
                                  false,                                          // Should interpolate
                                  kCGRenderingIntentDefault);                     // Intent
</code></pre>

<p>  NSBitmapImageRep <em>bitmapRep = [[NSBitmapImageRep alloc] initWithCGImage:imageRef];
  NSImage </em>image = [[NSImage alloc] init];
  [image addRepresentation:bitmapRep];</p>

<p>  CGImageRelease(imageRef);
  CGDataProviderRelease(provider);
  CGColorSpaceRelease(colorSpace);</p>

<p>  return image;
}</p></li>
</ul>


<p>@end</p>

<p>```</p>

<p>完成以上步骤后，恭喜你，你可以在源代码中自由地调用OpenCV的函数了。</p>

<h2>在iOS系统中使用OpenCV</h2>

<h4>下载或编译opencv2.framework</h4>

<p>接下来介绍如何在iOS程序中使用OpenCV。在iOS上使用最新的OpenCV库比较简单，进入<a href="http://opencv.org/">opencv的官网</a>，下载build好的名为opencv2.framework即可（<a href="http://sourceforge.net/projects/opencvlibrary/files/opencv-ios/2.4.3/opencv2.framework.zip/download?utm_expid=6384-3">下载地址</a>）。</p>

<p>如果你比较喜欢折腾，也可以自行下载opencv的源码，在本地编译opencv2.framework。<a href="http://docs.opencv.org/trunk/doc/tutorials/introduction/ios_install/ios_install.html#ios-installation">这里</a>有官方网站的教程，步骤非常简单，不过我照着它的教程尝试了一下失败了。感觉还是XCode编译器与OpenCV代码的兼容性问题，所以就没有继续研究了。</p>

<h4>在iOS程序中使用OpenCV</h4>

<p>新建一个iOS工程，将opencv2.framework直接拖动到工程中。然后，你需要在Build Settings中，将“C++ Standard Library”设置成libstdc++。</p>

<p>因为opencv中的MIN宏和UIKit的MIN宏有冲突。所以需要在.pch文件中，先定义opencv的头文件，否则会有编译错误。将工程的.pch文件内容修改成如下所示：</p>

<p>``` objc</p>

<h1>import &lt;Availability.h></h1>

<h1>ifdef __cplusplus</h1>

<pre><code>#import &lt;opencv2/opencv.hpp&gt;
</code></pre>

<h1>endif</h1>

<h1>ifdef <strong>OBJC</strong></h1>

<pre><code>#import &lt;UIKit/UIKit.h&gt;
#import &lt;Foundation/Foundation.h&gt;
</code></pre>

<h1>endif</h1>

<p>```</p>

<p>把上面的设置都做好后，就可以在需要的使用OpenCV库的地方，加上opencv的头文件引用即可：</p>

<p>``` objc</p>

<h1>import "opencv2/opencv.hpp"</h1>

<p>```</p>

<p>还是那句话，如果你的源文件扩展名是.m的，你还需要改成.mm，这样编译器才知道你将会在该文件中混合使用C++语言和Objective-C语言。</p>

<p>同样，iOS程序内部通常用UIImage表示图片，而OpenCV处理图象需要的格式是cv::Mat，你会需要下面这个Addition来在cv::Mat和UIImage格式之间相互转换。该代码来自<a href="https://github.com/aptogo/OpenCVForiPhone">aptogo的开源代码</a>，他的版权信息在源码头文件中。</p>

<p>UIImage+OpenCV.h 文件：
``` objc
//
//  UIImage+OpenCV.h
//  OpenCVClient
//
//  Created by Robin Summerhill on 02/09/2011.
//  Copyright 2011 Aptogo Limited. All rights reserved.
//
//  Permission is given to use this source code file without charge in any
//  project, commercial or otherwise, entirely at your risk, with the condition
//  that any redistribution (in part or whole) of source code must retain
//  this copyright and permission notice. Attribution in compiled projects is
//  appreciated but not required.
//</p>

<h1>import &lt;UIKit/UIKit.h></h1>

<p>@interface UIImage (UIImage_OpenCV)</p>

<p>+(UIImage *)imageWithCVMat:(const cv::Mat&amp;)cvMat;
-(id)initWithCVMat:(const cv::Mat&amp;)cvMat;</p>

<p>@property(nonatomic, readonly) cv::Mat CVMat;
@property(nonatomic, readonly) cv::Mat CVGrayscaleMat;</p>

<p>@end</p>

<p>```</p>

<p>UIImage+OpenCV.mm 文件：
``` objc
//
//  UIImage+OpenCV.mm
//  OpenCVClient
//
//  Created by Robin Summerhill on 02/09/2011.
//  Copyright 2011 Aptogo Limited. All rights reserved.
//
//  Permission is given to use this source code file without charge in any
//  project, commercial or otherwise, entirely at your risk, with the condition
//  that any redistribution (in part or whole) of source code must retain
//  this copyright and permission notice. Attribution in compiled projects is
//  appreciated but not required.
//</p>

<h1>import "UIImage+OpenCV.h"</h1>

<p>static void ProviderReleaseDataNOP(void <em>info, const void </em>data, size_t size)
{</p>

<pre><code>// Do not release memory
return;
</code></pre>

<p>}</p>

<p>@implementation UIImage (UIImage_OpenCV)</p>

<p>-(cv::Mat)CVMat
{</p>

<pre><code>CGColorSpaceRef colorSpace = CGImageGetColorSpace(self.CGImage);
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;

cv::Mat cvMat(rows, cols, CV_8UC4); // 8 bits per component, 4 channels

CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNoneSkipLast |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), self.CGImage);
CGContextRelease(contextRef);

return cvMat;
</code></pre>

<p>}</p>

<p>-(cv::Mat)CVGrayscaleMat
{</p>

<pre><code>CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceGray();
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;

cv::Mat cvMat = cv::Mat(rows, cols, CV_8UC1); // 8 bits per component, 1 channel

CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNone |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), self.CGImage);
CGContextRelease(contextRef);
CGColorSpaceRelease(colorSpace);

return cvMat;
</code></pre>

<p>}</p>

<ul>
<li><p>(UIImage *)imageWithCVMat:(const cv::Mat&amp;)cvMat
{
  return [[[UIImage alloc] initWithCVMat:cvMat] autorelease];
}</p></li>
<li><p>(id)initWithCVMat:(const cv::Mat&amp;)cvMat
{
  NSData *data = [NSData dataWithBytes:cvMat.data length:cvMat.elemSize() * cvMat.total()];</p>

<p>  CGColorSpaceRef colorSpace;</p>

<p>  if (cvMat.elemSize() == 1)
  {</p>

<pre><code>  colorSpace = CGColorSpaceCreateDeviceGray();
</code></pre>

  }
  else
  {

<pre><code>  colorSpace = CGColorSpaceCreateDeviceRGB();
</code></pre>

<p>  }</p>

<p>  CGDataProviderRef provider = CGDataProviderCreateWithCFData((CFDataRef)data);</p>

<p>  CGImageRef imageRef = CGImageCreate(cvMat.cols,                                     // Width</p>

<pre><code>                                  cvMat.rows,                                     // Height
                                  8,                                              // Bits per component
                                  8 * cvMat.elemSize(),                           // Bits per pixel
                                  cvMat.step[0],                                  // Bytes per row
                                  colorSpace,                                     // Colorspace
                                  kCGImageAlphaNone | kCGBitmapByteOrderDefault,  // Bitmap info flags
                                  provider,                                       // CGDataProviderRef
                                  NULL,                                           // Decode
                                  false,                                          // Should interpolate
                                  kCGRenderingIntentDefault);                     // Intent   
</code></pre>

<p>  self = [self initWithCGImage:imageRef];
  CGImageRelease(imageRef);
  CGDataProviderRelease(provider);
  CGColorSpaceRelease(colorSpace);</p>

<p>  return self;
}</p></li>
</ul>


<p>@end</p>

<p>```</p>

<h2>总结</h2>

<p>上面2个环境搭建好后，你就可以在MacOS上试验各种图象处理算法，然后很方便地移值到iOS上。</p>

<p>一直觉得，图象和声音是移动设备上的特点和优势。因为移动设备没有了可以快速输入的键盘，屏幕也不大，在移动设备上，声音，图象和视频应该是相比文字更方便让人输入的东西。移动端APP应该利用好这些特点，才能设计出更加体贴的功能。</p>

<p>而且，通常情况下做图象处理都比较好玩，记得以前在学校做了一个在QQ游戏大厅自动下中国象棋的程序，其后台使用了网上下载的一个带命令行接口的象棋AI，然后我的代码主要做的事情就是识别象棋棋盘，然后将棋盘数据传给那个象棋AI，接着获得它返回的策略后，模拟鼠标点击来移动棋子。当时不懂什么图象算法，直接把棋子先截取下来保存，然后识别的时候做完全匹配，非常弱的办法，但是效果非常好，做出来也很好玩。嗯，所以文章最后，我想说的是：have fun!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[粉笔网iPhone端使用的第三方开源库]]></title>
    <link href="http://blog.devtang.com/blog/2012/10/09/3rd-libs-used-in-fenbi-app/"/>
    <updated>2012-10-09T15:30:00+08:00</updated>
    <id>http://blog.devtang.com/blog/2012/10/09/3rd-libs-used-in-fenbi-app</id>
    <content type="html"><![CDATA[<h2>前言</h2>

<p>最近有朋友问我粉笔网iPhone端使用了哪些第三方的开源库。我在这儿整理了一下，分享给大家。</p>

<p><img src="/images/fenbi_libs.png"></p>

<!-- more -->


<h3>ASIHttpRequest</h3>

<p><a href="http://allseeing-i.com/ASIHTTPRequest/">ASIHttpRequest</a> 是一个被广泛使用的第三方网络访问开源库。用于提供更加友好的网络访问接口。相信很多搞iOS开发的朋友都用过它。
ASIHttpRequest 的主要使用文档可以<a href="http://allseeing-i.com/ASIHTTPRequest/How-to-use">参考这里</a>。</p>

<p>另外，由于ASIHTTPRequest的作者已经公开说明不再维护这个开源项目，并且该项目已经一年多没有更新了，所以我一直在寻找替代的开源库。不过现在暂时还没有找到更好的。</p>

<h3>RegexKit</h3>

<p><a href="http://regexkit.sourceforge.net/">RegexKit</a>是一个正则表达式工具类。提供强大的正则表达式匹配和替换功能。我们主要使用它来对类似微博的正文替换工作。例如将 @某某 换成带链接的，将图片的URL换成img标签等。</p>

<p>同时，开源库MGTemplateEngine也依赖于此库。附上<a href="http://regexkit.sourceforge.net/Documentation/index.html">RegexKit4.0的官方文档教程</a>。</p>

<h3>MGTemplateEngine</h3>

<p><a href="http://svn.cocoasourcecode.com/MGTemplateEngine">MGTemplateEngine</a>是一个模版引擎。我们主要使用它来生成单条微博页的内容。我们的单条微博页打算用UIWebView来显示，所以内容需要用模版渲染成HTML格式。MGTemplateEngine的模版语言比较象：Smarty, FreeMarker 和 Django的模版语言。</p>

<p>MGTemplateEngine的作者官方博客在<a href="http://mattgemmell.com/2008/05/20/mgtemplateengine-templates-with-cocoa/">这里</a>。</p>

<p>我们在使用时，对此开源库的Filter类进行了修改，主要增加了3个自定义的filter，用于提供我们的格式化时间，转义html和过滤空头象的用户的方式。</p>

<h3>JSONKit</h3>

<p><a href="https://github.com/johnezang/JSONKit">JSONKit</a>是一个比较高效的JSON解析库。我之前比较过各大JSON解析库的性能（<a href="http://blog.devtang.com/blog/2012/05/05/do-not-use-sbjson/">文章在此</a>），JSONKit算是非常不错的，大概的使用示例如下：</p>

<p>``` objc</p>

<h1>import "JSONKit.h"</h1>

<p>NSString <em>path = [[NSBundle mainBundle] pathForResource:@"data" ofType:@"json"];
NSData </em>content = [NSData dataWithContentsOfFile:path];
NSDictionary <em>kitData = [content objectFromJSONData];
NSString </em>kitString = [kitData JSONString];
```</p>

<h3>GTMNSString</h3>

<p><a href="https://code.google.com/p/google-toolbox-for-mac/">GTMNSString</a>主要用于转义HTML中的特殊字符。以防止XSS攻击。</p>

<h3>FMDB</h3>

<p><a href="https://github.com/ccgus/fmdb">FMDB</a>是一个sqlite数据库封装类，需要加入 libsqlite3.dylib 依赖以及引入 sqlite3.h 头文件即可。在使用上非常简单。如下是一个例子：</p>

<p>``` objc
NSString * docsdir = [NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES) lastObject];
NSString * dbpath = [docsdir stringByAppendingPathComponent:@"user.sqlite"];
FMDatabase * db = [FMDatabase databaseWithPath:dbpath];
[db open];
FMResultSet * rs = [db executeQuery:@"select * from People"];
while ([rs next]) {</p>

<pre><code>NSLog(@"%@ %@",
[rs stringForColumn:@"firstname"],
[rs stringForColumn:@"lastname"]);
</code></pre>

<p>}
[db close];
```</p>

<h3>BBCustomBackButtonViewController</h3>

<p><a href="https://github.com/typeoneerror/BBCustomBackButtonViewController">BBCustomBackButtonViewController</a> 是用于在ios4上提供自定义的NavigationBar按钮的开源库。使用上异常简单，只需要让自己的ViewController继承它就可以了。</p>

<p>我对BBCustomBackButtonViewController进行了修改，主要是改动它的自定义的按钮的样式，使其和我们的风格一致。</p>

<h3>MTStatusBarOverlay</h3>

<p><a href="https://github.com/myell0w/MTStatusBarOverlay">MTStatusBarOverlay</a> 是一个在iphone的顶部status bar显示消息的开源库。示例代码如下：</p>

<p>``` objc
+ (void)showCompletedTextOnStatusBar:(NSString *)text {</p>

<pre><code>NSString * message = [NSString stringWithFormat:@"%@成功", text];
MTStatusBarOverlay *overlay = [MTStatusBarOverlay sharedInstance];
overlay.animation = MTStatusBarOverlayAnimationFallDown;
overlay.detailViewMode = MTDetailViewModeHistory;
[overlay postImmediateFinishMessage:message duration:2.0 animated:YES];
overlay.progress = 1.0;
</code></pre>

<p>}
```</p>

<p>但是stackoverflow上说，有项目因为这个审核被拒，但是新浪微博明显采用了此UI方案，所以我们还是大胆用了这个库。后来，我们也顺利通过了审核。</p>

<h3>MBProgressHUD</h3>

<p><a href="https://github.com/jdg/MBProgressHUD">MBProgressHUD</a> 是一个用于显示灰色的加载进度或结果的类。与系统自带的UIAlertView相比，MBProgressHUD由于背影是黑色的，所以视觉上不是那么强烈。我们主要用它来显示一些加载中的提示，以及一些自已会消失的操作结果（例如网络失败等）。</p>

<h3>NSStringWrapper</h3>

<p>因为自己有多年Java开发的经历，我还是不太习惯Objective-C连基本的字符串操作都要查文档，而我自己又记不住老长的方法名，所以我把Objective-C的字符串基本操作都封装成了Java风格的方法调用。这部分是很早前拿周末时间在家里写的，所以是开源的，<a href="https://github.com/tangqiaoboy/xcode_tool/tree/master/NSStringWrappeer">源代码地址</a>。</p>

<h3>EGOTableViewPullRefresh</h3>

<p><a href="https://github.com/enormego/EGOTableViewPullRefresh">EGOTableViewPullRefresh</a> 一个开源的下拉刷新组件。我对它进行了改进，增加了强制刷新功能。</p>

<h3>LoadMoreTableFooterView</h3>

<p><a href="https://github.com/sishen/LoadMoreTableFooterView">LoadMoreTableFooterView</a> 一个开源的上拉加载更多的组件。我做了少量修改，以便让它支持iPhone5的分辨率。</p>

<h3>zepto.js</h3>

<p><a href="http://zeptojs.com/">zepto</a>是一个类似JQuery的javascript开源库，用于实现css选择器和一些dom操作。它的api几乎和JQuery完全一样，优点是体积小巧。</p>

<h3>ejs</h3>

<p><a href="http://embeddedjs.com/getting_started.html">ejs</a>一个js端的模版库。我们主要用于渲染一些UIWebview中异步加载的内容。例如笔记的评论，问题的答案。</p>

<h2>总结</h2>

<p>希望上面的开源库能对你有用。最后分享一张粉笔网全站用到的所有开源项目的图片。</p>

<p><img src="/images/opensource.jpg"></p>
]]></content>
  </entry>
  
</feed>
